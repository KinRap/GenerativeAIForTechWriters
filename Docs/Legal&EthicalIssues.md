---
title: Legal & Ethical Issues
layout: default
parent: Risks & Limitations
nav_order: 6
---
<img src="../Images/4.png" alt="Header Risk And Limitations" width="100%">

## **Legal & Ethical Issues** ##

***

The increasing use of GenAI raises a number of ethical and legal concerns and challenges, including those related to intellectual property, data privacy, and liability for errors or misuse of the technology. According to the [Artificial Intelligence Index Report](https://aiindex.stanford.edu/wp-content/uploads/2023/04/HAI_AI-Index-Report_2023.pdf), in 2023, "25 AI-related regulations were enacted in the US, growing the total number by 56.3%. Compare that to 2016, when just one was introduced. The number of AI-related regulations passed by the EU jumped from 22 in 2022 to 32 in 2023. Despite this growth, approved EU regulations were at their peak in 2021, when 46 were passed#. These numbers show how many ethical and legal issues relate to the use of artificial intelligence. It is certain that the more such documents are created, the more doubts will be dispelled.

### Who is the author? ###
Content should ideally be sourced and attributed to its original authors, but GenAI often does not attribute either authorship or sources of its content. This means that the recipient often does not know who generated the given content. Users may expect documentation written by humans. Furthermore, the question of intellectual property rights to content generated by AI remains open. It is complex: is it the creator of the AI, the user inputting the data, or the company owning the AI tool?

For example, *OpenAI* (the company behind *ChatGPT*) does not claim ownership of generated content. In their [*Service terms*](https://openai.com/policies/service-terms/), we can read: "OpenAI hereby assigns to you all its right, title, and interest in and to Output." But if the data on which GenAI was trained has an owner who is not credited, are we really taking over their rights?


### Property rights ###
Most words and images provided for training AI are copyrighted. Therefore, using this data should involve compensation for the authors. However, this is often not the case.

This problem should also be considered from another angle in the case of content creation. Many GenAI tools do not provide authors or sources from which they draw information. We never know whether the tool's response to a prompt will be plagiarism, especially when we notice that GenAI can respond to the same query in different ways. AI can generate content very similar to documents written previously by humans. This can lead to accusations of plagiarism, especially if you present these texts as your own.

Additionally, publishing AI-generated documents can result in losses in terms of search engine optimization (SEO). Search engines tend to penalize content that is too similar to others.

An attempt to circumvent this problem often refers to the doctrine of ***fairness***, which distinguishes three models: ***fair use*** (USA), ***fair dealing*** (Commonwealth), and ***fair practice*** (most of Europe). According to this doctrine, it is legal to use excerpts of text, code, or images for personal use. However, if the model generates output data similar to data protected by copyright, this rule does not apply. it can be indicated as ***fair use*** according to current standards, if the copied amount is small, the entire product differs significantly from the original, or the code is sufficiently transformed, Otherwise, copying code is subject to different rules, aside from issues related to the functionality of the code.

### Manipulation ### 
Generative AI can be used for malicious purposes, such as generating fake news, deep fakes, or other types of false information. This raises ethical concerns about the potential misuse of this technology.

There is a possibility that AI tools will perpetuate biases present in the data on which they were trained. This can introduce unintended but significant ethical issues into the documentation. Inaccurate or misleading information in technical documents can lead to legal consequences. Since AI lacks the human ability to fully understand legal implications, the responsibility for verifying the information lies with the writer.

For example, an AI system that generates technical documents based on user data might produce biased or discriminatory content that violates the user's rights or preferences.

Cybersecurity breaches can also compromise the integrity of AI-powered writing tools, leading to misinformation or data loss.

GenAI systems can be used to generate realistic and convincing fake images, videos, and texts that can be used to spread misinformation or propaganda. Therefore, it is essential to develop security measures and prevent the malicious use of GenAI.

GenAI should be trained not to respond to vulgar or contradictory queries. It is also necessary to regularly update tools through reviews and training as new ethical issues arise.

### Liability ###
In legal terms, the issue of liability for errors and damages caused by content generated by GenAI is often discussed. This can include intellectual, social, moral, financial, and even health-related losses. Who is responsible for them â€“ the creator of the AI, the user, or the company implementing the AI?

Every user who uses GenAI to generate and publish content should adhere to moral principles such as responsibility, transparency, and fairness. The first step to compliance is to disclose to the recipient when content is generated by GenAI.
