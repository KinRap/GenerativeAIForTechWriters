---
title: Falsification
layout: default
parent: Risks & Limitations
nav_order: 3
---
<img src="../Images/4.png" alt="Header Risk And Limitations" width="100%">

## **Falsification** ##
***

AI can sometimes produce incorrect or contradicting information, a phenomenon referred to as data hallucination. 
<!-- Tu potrzebne objaśnienie, że AI generuje tekst, nie rozumiejąc jego znaczenia, dlatego nawet z dobrych treści może wygenerować błędne -->

Another problematic issue is the lack of high-quality information. Because AI is dealing with sophisticated technical texts containing facts and assumptions, it becomes difficult to differentiate between the two. GenAI can produce textual content that might be quite interesting to readers, but is not entirely true. Moreover, given that technology continues to develop at a fast pace, AI may use information from several years ago and, therefore, generate irrelevant output.

Other drawbacks or risks of using GenAI models are that they may learn discrimination and partiality from the internet data, and replicate the same in generated content. Currently, GenAI lacks the ability to classify content as discriminatory because it lacks a mechanism for ethical judgment. Therefore, when using them in technical writing, there could be an inclination to introduce bias into the work, where stereotypical pronoun usage or even role portrayals could be encouraged.

Additionally, GenAI might be skewed towards providing many results for some topics while barely providing any for others. Lack of data gathering mechanisms across different cultures and their diversities may lead to GenAI being exposed to content that is obscene or in contravention to the culture and the beliefs of the target populace.

While AI writing systems have improved, errors may still occur because of limited data, algorithmic constraints, and data processing issues, among other factors. There may be cases where GenAI is not exactly logical and fails to correctly interpret the meaning of a given subject matter, which could result in misinformation or even illogical sentences.
