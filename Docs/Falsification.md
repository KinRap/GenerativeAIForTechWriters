---
title: Falsification
layout: default
parent: Risks & Limitations
nav_order: 3
---
<img src="../Images/4.png" alt="Header Risk And Limitations" width="100%">

## **Falsification** ##
***

AI can sometimes produce incorrect or contradicting information, a phenomenon referred to as data hallucination. 

GenAI creates text by recognizing patterns from large amounts of data. However, it doesn’t really "understand" the meaning of what it's writing like humans do. It mainly predicts the next word or phrase based on what it has been given. Because of this, AI can write responses that make sense and seem smart, but it might still give incorrect or misleading information, even if it starts with good material. Since AI doesn’t truly understand the text, it can’t always guarantee that the information it provides is accurate or relevant.

Another problematic issue is the lack of high-quality information. Because AI is dealing with sophisticated technical texts containing facts and assumptions, it becomes difficult to differentiate between the two. GenAI can produce textual content that might be quite interesting to readers, but is not entirely true. Moreover, given that technology continues to develop at a fast pace, AI may use information from several years ago and, therefore, generate irrelevant output.

Other drawbacks or risks of using GenAI models are that they may learn discrimination and partiality from the internet data, and replicate the same in generated content. Currently, GenAI lacks the ability to classify content as discriminatory because it lacks a mechanism for ethical judgment. Therefore, when using them in technical writing, there could be an inclination to introduce bias into the work, where stereotypical pronoun usage or even role portrayals could be encouraged.

Additionally, GenAI might be skewed towards providing many results for some topics while barely providing any for others. Lack of data gathering mechanisms across different cultures and their diversities may lead to GenAI being exposed to content that is obscene or in contravention to the culture and the beliefs of the target populace.

While AI writing systems have improved, errors may still occur because of limited data, algorithmic constraints, and data processing issues, among other factors. There may be cases where GenAI is not exactly logical and fails to correctly interpret the meaning of a given subject matter, which could result in misinformation or even illogical sentences.
