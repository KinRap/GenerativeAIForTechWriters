---
title: Falsification
layout: default
parent: Risks & Limitations
nav_order: 3
---

## **Falsification** ##

It is evident that AI offers numerous advantages, but it is still important to acknowledge its disadvantages. It should be noted that AI can sometimes produce incorrect or contradicting information, a phenomenon referred to as data hallucination. 

Some of the drawbacks or risks of using GenAI models are that they may learn discrimination and partiality from internet data and replicate the same in generated content. Currently, GenAI lacks the ability to classify content as discriminatory because it lacks a mechanism for ethical judgment. Therefore, when using them in technical writing, there could be an inclination to introduce bias into the work, where stereotypical pronoun usage or even role portrayals could be encouraged.

Additionally, GenAI might be skewed towards providing a lot of results for some topics while barely providing any results for certain subjects. Lack of data gathering mechanisms across different cultures and their diversities may lead to GenAI being exposed to content that is obscene or in contravention of the culture and the beliefs of the target populace.

Another problematic issue is the lack of high-quality information. Because AI is dealing with sophisticated technical texts containing facts and complete fiction, it becomes difficult to differentiate between the two. For example, GenAI can produce textual content that might be quite interesting to readers but is not entirely true. Moreover, given that technology continues to develop at a fast pace, AI may use some information from several years ago and, therefore, generate irrelevant information.

Additionally, the reliability of the information provided by AI is another concern where AI might present misleading or even wrong information that proves to be a challenge in technical writing. This means that performing adequate work to create viable documents quickly can prove to be very complicated as essential information may be missed, leading to fines, accidents, or other future-related problems.

While AI writing systems have improved, errors may still occur because of limited data, algorithmic constraints, and data processing issues, among other factors. There may be cases where GenAI is not exactly logical and fails to correctly interpret the meaning of a given subject matter, which could result in misinformation or even illogical sentences.
