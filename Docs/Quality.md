---
title: Quality
layout: default
parent: Risks & Limitations
nav_order: 2
---

## **Quality** ##

The quality of content in technical documentation, particularly instructions and procedures, is crucial. A single word left out or put in the wrong context usually results in misunderstanding, machine breakdowns, accidents, injuries, and other issues. This underscores the challenge of using GenAI in technical writing. It is therefore important for any publication to have mechanisms in place to maintain high standards of the material it disseminates.

The quality of the content should demonstrate elements of clarity, accuracy, relevance, and coherence. Lack of quality can lead to misunderstandings, mistakes, dissatisfaction, and frustration among users of technical documents. Automatically generated content is produced by a computer and thus needs to be reviewed by a technical writer to ensure the content's quality and coherence. Given that GenAI only understands the data it has been trained on, its documentation can sometimes be meaningless or simply false. Therefore, GenAI should be used as a base for writing, with technical authors adding the ‘human touch.’

Technical topics can be very informative and detailed. Another issue with using GenAI tools is that their readability is frequently linked to mimicking human language, which may be more appropriate for narrative guidelines and can lead to difficulties for the reader. Technical writers are aware of the guidelines that organizations need to follow to avoid fines or operational interruptions.

Since GenAI writers do not possess the human spark in their writing, the generated text may sound as if it were written by robots, devoid of the human feel. Emotional recognition in the text is still poorly handled by GenAI, and its gaps affect the text’s quality, making it look dull and uninteresting. This requires the attention of the user, making it unappealing to them.

It is, therefore, necessary to understand different contexts so that the specificity of a particular field can be considered when working with users from different backgrounds. The meanings of words can change according to the receiver, context, and even the goal of the communication.

Non-defective outputs are not guaranteed from generative AI systems, as the decisions may have flaws or consist of errors and artifacts due to low or poor-quality data, poor training, or the use of complex models. Possible complications include a reduction in the skills of real human writers who depend on AI tools and the possibility that drafts produced by AI tools may not be carefully checked.

For new materials, guidance is required on the new topic to make the cross-reference from the content to existing domain knowledge. Difficulties with more complex formats can be counterintuitive and present a challenge to GenAI. Content generators can translate texts but may fail to grasp the nuances of written language as effectively as humans do. While they can be a good starting point for translation, relying on them can cause issues on an international level.

Additionally, GenAI can generate not only text but also images, voices, and videos. However, these outputs are not always accurate and often need fine-tuning.

It is important to remember that the quality of documentation affects the perception of both the organization and its clients, as well as the technical writers. Even the smallest mistake can have serious consequences, including risking human lives. Therefore, the quality of the created documentation is overseen not only by the technical writer but also by the **SME (Subject Matter Expert)**. Relying solely on Generative AI to create content can pose a threat to everyone.
